import os
import json
import logging
from datetime import datetime
from dotenv import load_dotenv
import asyncio

from scripts.ai_async import batch_generate

# ---------------------- ì„¤ì • ë¡œë”© ----------------------
load_dotenv()
KEYWORD_JSON_PATH = os.getenv("KEYWORD_OUTPUT_PATH", "data/keyword_output_with_cpc.json")
HOOK_OUTPUT_PATH = os.getenv("HOOK_OUTPUT_PATH", "data/generated_hooks.json")
FAILED_HOOK_PATH = os.getenv("FAILED_HOOK_PATH", "logs/failed_hooks.json")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
CONCURRENCY = int(os.getenv("CONCURRENCY", "5"))

# ---------------------- ë¡œê¹… ì„¤ì • ----------------------
logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s:%(message)s')

# ---------------------- GPT í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜ ----------------------
def generate_hook_prompt(keyword, topic, source, score, growth, mentions):
    base = f"""
    ì£¼ì œ: {keyword}
    ì¶œì²˜: {source}
    íŠ¸ë Œë“œ ì ìˆ˜: {score}, ì„±ìž¥ë¥ : {growth}, íŠ¸ìœ— ìˆ˜: {mentions}
    ì´ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ:
    - ìˆí¼ ì˜ìƒì˜ í›„í‚¹ ë¬¸ìž¥ 2ê°œ
    - ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ì˜ 3ë¬¸ë‹¨ ì´ˆì•ˆ
    - YouTube ì˜ìƒ ì œëª© ì˜ˆì‹œ 2ê°œ
    ë¥¼ ë§ˆì¼€íŒ…ì ìœ¼ë¡œ ëŒë¦¬ëŠ” ë¬¸ìž¥ìœ¼ë¡œ ìƒì„±í•´ì¤˜. ë§íˆ¬ëŠ” ì¹œê·¼í•˜ë©´ì„œë„ ì „ë¬¸ê°€ì²˜ëŸ¼.
    """
    return base.strip()

# ---------------------- GPT ë¹„ë™ê¸° í˜¸ì¶œ ----------------------


# ---------------------- ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ ----------------------
async def _generate_hooks():
    if not OPENAI_API_KEY:
        logging.error("â— OpenAI API í‚¤ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. .env íŒŒì¼ í™•ì¸ í•„ìš”")
        return

    try:
        with open(KEYWORD_JSON_PATH, 'r', encoding='utf-8') as f:
            data = json.load(f)
            keywords = data.get("filtered_keywords", [])
    except Exception as e:
        logging.error(f"â— í‚¤ì›Œë“œ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        return

    existing = {}
    if os.path.exists(HOOK_OUTPUT_PATH):
        try:
            with open(HOOK_OUTPUT_PATH, 'r', encoding='utf-8') as f:
                existing_data = json.load(f)
                for entry in existing_data:
                    existing[entry['keyword']] = entry
        except Exception as e:
            logging.warning(f"ê¸°ì¡´ ê²°ê³¼ ë¡œë”© ì‹¤íŒ¨: {e}")

    new_output: list[dict] = []
    failed_output: list[dict] = []
    skipped, success, failed = 0, 0, 0

    prompts = []
    items = []
    for item in keywords:
        keyword = item.get('keyword')
        if not keyword:
            logging.warning("â›” ë¹ˆ í‚¤ì›Œë“œ í•­ëª©, ê±´ë„ˆëœë‹ˆë‹¤.")
            continue

        if keyword in existing:
            logging.info(f"â­ï¸ ì¤‘ë³µ ìŠ¤í‚µ: {keyword}")
            skipped += 1
            continue

        prompt = generate_hook_prompt(
            keyword=keyword,
            topic=keyword.split()[0],
            source=item.get('source'),
            score=item.get('score', 0),
            growth=item.get('growth', 0),
            mentions=item.get('mentions', 0)
        )
        prompts.append(prompt)
        items.append(keyword)

    responses = await batch_generate(prompts, concurrency=CONCURRENCY)

    for keyword, prompt, response in zip(items, prompts, responses):
        result = {
            "keyword": keyword,
            "hook_prompt": prompt,
            "timestamp": datetime.utcnow().isoformat() + 'Z'
        }

        if response:
            lines = response.split('\n')
            result.update({
                "hook_lines": lines[0:2],
                "blog_paragraphs": lines[2:5],
                "video_titles": lines[5:],
                "generated_text": response
            })
            new_output.append(result)
            logging.info(f"âœ… ìƒì„± ì™„ë£Œ: {keyword}")
            success += 1
        else:
            result["generated_text"] = None
            result["error"] = "GPT ì‘ë‹µ ì‹¤íŒ¨"
            failed_output.append(result)
            logging.error(f"âŒ ìƒì„± ì‹¤íŒ¨: {keyword}")
            failed += 1

    full_output = list(existing.values()) + new_output
    os.makedirs(os.path.dirname(HOOK_OUTPUT_PATH), exist_ok=True)
    with open(HOOK_OUTPUT_PATH, 'w', encoding='utf-8') as f:
        json.dump(full_output, f, ensure_ascii=False, indent=2)

    if failed_output:
        os.makedirs(os.path.dirname(FAILED_HOOK_PATH), exist_ok=True)
        with open(FAILED_HOOK_PATH, 'w', encoding='utf-8') as f:
            json.dump(failed_output, f, ensure_ascii=False, indent=2)
        logging.warning(f"âš ï¸ ì‹¤íŒ¨ í›„í‚¹ ì €ìž¥ ì™„ë£Œ: {FAILED_HOOK_PATH}")

    logging.info("ðŸ“Š ìƒì„± ìž‘ì—… ìš”ì•½")
    logging.info(f"ì´ í‚¤ì›Œë“œ: {len(keywords)} | ì„±ê³µ: {success} | ì¤‘ë³µìŠ¤í‚µ: {skipped} | ì‹¤íŒ¨: {failed}")

    logging.info(f"ðŸŽ‰ í›„í‚¹ ë¬¸ìž¥ ì €ìž¥ ì™„ë£Œ: {HOOK_OUTPUT_PATH}")


def generate_hooks() -> None:
    asyncio.run(_generate_hooks())

if __name__ == "__main__":
    generate_hooks()
