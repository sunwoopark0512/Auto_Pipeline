import os
import json
import logging
from datetime import datetime
from dotenv import load_dotenv
import asyncio
import openai

# ---------------------- ÏÑ§Ï†ï Î°úÎî© ----------------------
load_dotenv()
KEYWORD_JSON_PATH = os.getenv("KEYWORD_OUTPUT_PATH", "data/keyword_output_with_cpc.json")
HOOK_OUTPUT_PATH = os.getenv("HOOK_OUTPUT_PATH", "data/generated_hooks.json")
FAILED_HOOK_PATH = os.getenv("FAILED_HOOK_PATH", "logs/failed_hooks.json")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
API_DELAY = float(os.getenv("API_DELAY", "1.0"))

client = openai.AsyncOpenAI(api_key=OPENAI_API_KEY)

# ---------------------- Î°úÍπÖ ÏÑ§Ï†ï ----------------------
logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s:%(message)s')

# ---------------------- ÎπÑÎèôÍ∏∞ Î†àÏù¥Ìä∏ Î¶¨ÎØ∏ÌÑ∞ ----------------------
class RateLimiter:
    def __init__(self, delay: float):
        self.delay = delay
        self._lock = asyncio.Lock()
        self._next_time = 0.0

    async def wait(self):
        async with self._lock:
            now = asyncio.get_event_loop().time()
            if now < self._next_time:
                await asyncio.sleep(self._next_time - now)
            self._next_time = asyncio.get_event_loop().time() + self.delay

rate_limiter = RateLimiter(API_DELAY)

# ---------------------- GPT ÌîÑÎ°¨ÌîÑÌä∏ ÏÉùÏÑ± Ìï®Ïàò ----------------------
def generate_hook_prompt(keyword, topic, source, score, growth, mentions):
    base = f"""
    Ï£ºÏ†ú: {keyword}
    Ï∂úÏ≤ò: {source}
    Ìä∏Î†åÎìú Ï†êÏàò: {score}, ÏÑ±Ïû•Î•†: {growth}, Ìä∏Ïúó Ïàò: {mentions}
    Ïù¥ Ï†ïÎ≥¥Î•º Í∏∞Î∞òÏúºÎ°ú:
    - ÏàèÌèº ÏòÅÏÉÅÏùò ÌõÑÌÇπ Î¨∏Ïû• 2Í∞ú
    - Î∏îÎ°úÍ∑∏ Ìè¨Ïä§Ìä∏Ïùò 3Î¨∏Îã® Ï¥àÏïà
    - YouTube ÏòÅÏÉÅ Ï†úÎ™© ÏòàÏãú 2Í∞ú
    Î•º ÎßàÏºÄÌåÖÏ†ÅÏúºÎ°ú ÎÅåÎ¶¨Îäî Î¨∏Ïû•ÏúºÎ°ú ÏÉùÏÑ±Ìï¥Ï§ò. ÎßêÌà¨Îäî ÏπúÍ∑ºÌïòÎ©¥ÏÑúÎèÑ Ï†ÑÎ¨∏Í∞ÄÏ≤òÎüº.
    """
    return base.strip()

# ---------------------- GPT Ìò∏Ï∂ú Ìï®Ïàò (Ïû¨ÏãúÎèÑ Ìè¨Ìï®) ----------------------
async def get_gpt_response(prompt, retries: int = 3):
    for attempt in range(retries):
        try:
            await rate_limiter.wait()
            response = await client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
            )
            return response.choices[0].message.content
        except Exception as e:
            logging.warning(f"GPT Ìò∏Ï∂ú Ïã§Ìå® {attempt + 1}/{retries}: {e}")
            await asyncio.sleep(2)
    return None

# ---------------------- Î©îÏù∏ Ïã§Ìñâ Ìï®Ïàò ----------------------
async def process_keyword(item, existing):
    keyword = item.get('keyword')
    if not keyword:
        logging.warning("‚õî Îπà ÌÇ§ÏõåÎìú Ìï≠Î™©, Í±¥ÎÑàÎúÅÎãàÎã§.")
        return 'skipped', None

    if keyword in existing:
        logging.info(f"‚è≠Ô∏è Ï§ëÎ≥µ Ïä§ÌÇµ: {keyword}")
        return 'skipped', None

    prompt = generate_hook_prompt(
        keyword=keyword,
        topic=keyword.split()[0],
        source=item.get('source'),
        score=item.get('score', 0),
        growth=item.get('growth', 0),
        mentions=item.get('mentions', 0)
    )

    response = await get_gpt_response(prompt)

    result = {
        "keyword": keyword,
        "hook_prompt": prompt,
        "timestamp": datetime.utcnow().isoformat() + 'Z'
    }

    if response:
        lines = response.split('\n')
        result.update({
            "hook_lines": lines[0:2],
            "blog_paragraphs": lines[2:5],
            "video_titles": lines[5:],
            "generated_text": response
        })
        logging.info(f"‚úÖ ÏÉùÏÑ± ÏôÑÎ£å: {keyword}")
        return 'success', result
    else:
        result["generated_text"] = None
        result["error"] = "GPT ÏùëÎãµ Ïã§Ìå®"
        logging.error(f"‚ùå ÏÉùÏÑ± Ïã§Ìå®: {keyword}")
        return 'failed', result


async def generate_hooks():
    if not OPENAI_API_KEY:
        logging.error("‚ùó OpenAI API ÌÇ§Í∞Ä ÎàÑÎùΩÎêòÏóàÏäµÎãàÎã§. .env ÌååÏùº ÌôïÏù∏ ÌïÑÏöî")
        return

    try:
        with open(KEYWORD_JSON_PATH, 'r', encoding='utf-8') as f:
            data = json.load(f)
            keywords = data.get("filtered_keywords", [])
    except Exception as e:
        logging.error(f"‚ùó ÌÇ§ÏõåÎìú ÌååÏùº ÏùΩÍ∏∞ Ïò§Î•ò: {e}")
        return

    existing = {}
    if os.path.exists(HOOK_OUTPUT_PATH):
        try:
            with open(HOOK_OUTPUT_PATH, 'r', encoding='utf-8') as f:
                existing_data = json.load(f)
                for entry in existing_data:
                    existing[entry['keyword']] = entry
        except Exception as e:
            logging.warning(f"Í∏∞Ï°¥ Í≤∞Í≥º Î°úÎî© Ïã§Ìå®: {e}")

    new_output = []
    failed_output = []
    skipped = success = failed = 0

    tasks = [process_keyword(item, existing) for item in keywords]
    for status, result in await asyncio.gather(*tasks):
        if status == 'success':
            new_output.append(result)
            success += 1
        elif status == 'failed':
            failed_output.append(result)
            failed += 1
        else:
            skipped += 1

    full_output = list(existing.values()) + new_output
    os.makedirs(os.path.dirname(HOOK_OUTPUT_PATH), exist_ok=True)
    with open(HOOK_OUTPUT_PATH, 'w', encoding='utf-8') as f:
        json.dump(full_output, f, ensure_ascii=False, indent=2)

    if failed_output:
        os.makedirs(os.path.dirname(FAILED_HOOK_PATH), exist_ok=True)
        with open(FAILED_HOOK_PATH, 'w', encoding='utf-8') as f:
            json.dump(failed_output, f, ensure_ascii=False, indent=2)
        logging.warning(f"‚ö†Ô∏è Ïã§Ìå® ÌõÑÌÇπ Ï†ÄÏû• ÏôÑÎ£å: {FAILED_HOOK_PATH}")

    logging.info("üìä ÏÉùÏÑ± ÏûëÏóÖ ÏöîÏïΩ")
    logging.info(f"Ï¥ù ÌÇ§ÏõåÎìú: {len(keywords)} | ÏÑ±Í≥µ: {success} | Ï§ëÎ≥µÏä§ÌÇµ: {skipped} | Ïã§Ìå®: {failed}")
    logging.info(f"üéâ ÌõÑÌÇπ Î¨∏Ïû• Ï†ÄÏû• ÏôÑÎ£å: {HOOK_OUTPUT_PATH}")

if __name__ == "__main__":
    asyncio.run(generate_hooks())
