import os
import json
import logging
from datetime import datetime
from dotenv import load_dotenv
import asyncio
import openai

# ---------------------- ì„¤ì • ë¡œë”© ----------------------
load_dotenv()
KEYWORD_JSON_PATH = os.getenv("KEYWORD_OUTPUT_PATH", "data/keyword_output_with_cpc.json")
HOOK_OUTPUT_PATH = os.getenv("HOOK_OUTPUT_PATH", "data/generated_hooks.json")
FAILED_HOOK_PATH = os.getenv("FAILED_HOOK_PATH", "logs/failed_hooks.json")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
API_DELAY = float(os.getenv("API_DELAY", "1.0"))
CONCURRENT_REQUESTS = int(os.getenv("CONCURRENT_REQUESTS", "5"))

client = openai.AsyncOpenAI(api_key=OPENAI_API_KEY)

# ---------------------- ë¡œê¹… ì„¤ì • ----------------------
logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s:%(message)s')

# ---------------------- GPT í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜ ----------------------
def generate_hook_prompt(keyword, topic, source, score, growth, mentions):
    base = f"""
    ì£¼ì œ: {keyword}
    ì¶œì²˜: {source}
    íŠ¸ë Œë“œ ì ìˆ˜: {score}, ì„±ì¥ë¥ : {growth}, íŠ¸ìœ— ìˆ˜: {mentions}
    ì´ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ:
    - ìˆí¼ ì˜ìƒì˜ í›„í‚¹ ë¬¸ì¥ 2ê°œ
    - ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ì˜ 3ë¬¸ë‹¨ ì´ˆì•ˆ
    - YouTube ì˜ìƒ ì œëª© ì˜ˆì‹œ 2ê°œ
    ë¥¼ ë§ˆì¼€íŒ…ì ìœ¼ë¡œ ëŒë¦¬ëŠ” ë¬¸ì¥ìœ¼ë¡œ ìƒì„±í•´ì¤˜. ë§íˆ¬ëŠ” ì¹œê·¼í•˜ë©´ì„œë„ ì „ë¬¸ê°€ì²˜ëŸ¼.
    """
    return base.strip()

# ---------------------- GPT í˜¸ì¶œ í•¨ìˆ˜ (ì¬ì‹œë„ í¬í•¨) ----------------------
async def get_gpt_response(prompt: str, retries: int = 3) -> str | None:
    for attempt in range(retries):
        try:
            response = await client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
            )
            return response.choices[0].message.content
        except Exception as e:
            logging.warning(f"GPT í˜¸ì¶œ ì‹¤íŒ¨ {attempt + 1}/{retries}: {e}")
            await asyncio.sleep(2)
    return None

# ---------------------- ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ ----------------------
async def process_keyword(item: dict, existing: dict, semaphore: asyncio.Semaphore):
    keyword = item.get('keyword')
    if not keyword:
        logging.warning("â›” ë¹ˆ í‚¤ì›Œë“œ í•­ëª©, ê±´ë„ˆëœë‹ˆë‹¤.")
        return 'skipped', None

    if keyword in existing:
        logging.info(f"â­ï¸ ì¤‘ë³µ ìŠ¤í‚µ: {keyword}")
        return 'skipped', None

    prompt = generate_hook_prompt(
        keyword=keyword,
        topic=keyword.split()[0],
        source=item.get('source'),
        score=item.get('score', 0),
        growth=item.get('growth', 0),
        mentions=item.get('mentions', 0)
    )

    async with semaphore:
        response = await get_gpt_response(prompt)
        await asyncio.sleep(API_DELAY)

    result = {
        "keyword": keyword,
        "hook_prompt": prompt,
        "timestamp": datetime.utcnow().isoformat() + 'Z'
    }

    if response:
        lines = response.split('\n')
        result.update({
            "hook_lines": lines[0:2],
            "blog_paragraphs": lines[2:5],
            "video_titles": lines[5:],
            "generated_text": response
        })
        logging.info(f"âœ… ìƒì„± ì™„ë£Œ: {keyword}")
        return 'success', result
    else:
        result["generated_text"] = None
        result["error"] = "GPT ì‘ë‹µ ì‹¤íŒ¨"
        logging.error(f"âŒ ìƒì„± ì‹¤íŒ¨: {keyword}")
        return 'failed', result


async def generate_hooks():
    if not OPENAI_API_KEY:
        logging.error("â— OpenAI API í‚¤ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. .env íŒŒì¼ í™•ì¸ í•„ìš”")
        return

    try:
        with open(KEYWORD_JSON_PATH, 'r', encoding='utf-8') as f:
            data = json.load(f)
            keywords = data.get("filtered_keywords", [])
    except Exception as e:
        logging.error(f"â— í‚¤ì›Œë“œ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        return

    existing = {}
    if os.path.exists(HOOK_OUTPUT_PATH):
        try:
            with open(HOOK_OUTPUT_PATH, 'r', encoding='utf-8') as f:
                existing_data = json.load(f)
                for entry in existing_data:
                    existing[entry['keyword']] = entry
        except Exception as e:
            logging.warning(f"ê¸°ì¡´ ê²°ê³¼ ë¡œë”© ì‹¤íŒ¨: {e}")

    new_output = []
    failed_output = []
    skipped = success = failed = 0

    semaphore = asyncio.Semaphore(CONCURRENT_REQUESTS)
    tasks = [process_keyword(item, existing, semaphore) for item in keywords]

    for status, result in await asyncio.gather(*tasks):
        if status == 'skipped':
            skipped += 1
            continue
        if status == 'success' and result:
            new_output.append(result)
            success += 1
        elif status == 'failed' and result:
            failed_output.append(result)
            failed += 1

    full_output = list(existing.values()) + new_output
    os.makedirs(os.path.dirname(HOOK_OUTPUT_PATH), exist_ok=True)
    with open(HOOK_OUTPUT_PATH, 'w', encoding='utf-8') as f:
        json.dump(full_output, f, ensure_ascii=False, indent=2)

    if failed_output:
        os.makedirs(os.path.dirname(FAILED_HOOK_PATH), exist_ok=True)
        with open(FAILED_HOOK_PATH, 'w', encoding='utf-8') as f:
            json.dump(failed_output, f, ensure_ascii=False, indent=2)
        logging.warning(f"âš ï¸ ì‹¤íŒ¨ í›„í‚¹ ì €ì¥ ì™„ë£Œ: {FAILED_HOOK_PATH}")

    logging.info("ğŸ“Š ìƒì„± ì‘ì—… ìš”ì•½")
    logging.info(f"ì´ í‚¤ì›Œë“œ: {len(keywords)} | ì„±ê³µ: {success} | ì¤‘ë³µìŠ¤í‚µ: {skipped} | ì‹¤íŒ¨: {failed}")
    logging.info(f"ğŸ‰ í›„í‚¹ ë¬¸ì¥ ì €ì¥ ì™„ë£Œ: {HOOK_OUTPUT_PATH}")

if __name__ == "__main__":
    asyncio.run(generate_hooks())
