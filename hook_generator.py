import asyncio
import json
import logging
import os
from datetime import datetime

from dotenv import load_dotenv
import openai

# ---------------------- ì„¤ì • ë¡œë”© ----------------------
load_dotenv()
KEYWORD_JSON_PATH = os.getenv("KEYWORD_OUTPUT_PATH", "data/keyword_output_with_cpc.json")
HOOK_OUTPUT_PATH = os.getenv("HOOK_OUTPUT_PATH", "data/generated_hooks.json")
FAILED_HOOK_PATH = os.getenv("FAILED_HOOK_PATH", "logs/failed_hooks.json")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
API_DELAY = float(os.getenv("API_DELAY", "1.0"))
MAX_CONCURRENT_REQUESTS = int(os.getenv("MAX_CONCURRENT_REQUESTS", "5"))

openai.api_key = OPENAI_API_KEY

# ---------------------- ë¡œê¹… ì„¤ì • ----------------------
logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s:%(message)s')

# ---------------------- GPT í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜ ----------------------
def generate_hook_prompt(keyword, topic, source, score, growth, mentions):
    base = f"""
    ì£¼ì œ: {keyword}
    ì¶œì²˜: {source}
    íŠ¸ë Œë“œ ì ìˆ˜: {score}, ì„±ì¥ë¥ : {growth}, íŠ¸ìœ— ìˆ˜: {mentions}
    ì´ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ:
    - ìˆí¼ ì˜ìƒì˜ í›„í‚¹ ë¬¸ì¥ 2ê°œ
    - ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ì˜ 3ë¬¸ë‹¨ ì´ˆì•ˆ
    - YouTube ì˜ìƒ ì œëª© ì˜ˆì‹œ 2ê°œ
    ë¥¼ ë§ˆì¼€íŒ…ì ìœ¼ë¡œ ëŒë¦¬ëŠ” ë¬¸ì¥ìœ¼ë¡œ ìƒì„±í•´ì¤˜. ë§íˆ¬ëŠ” ì¹œê·¼í•˜ë©´ì„œë„ ì „ë¬¸ê°€ì²˜ëŸ¼.
    """
    return base.strip()

# ---------------------- GPT í˜¸ì¶œ í•¨ìˆ˜ (ì¬ì‹œë„ í¬í•¨) ----------------------
async def get_gpt_response(prompt: str, retries: int = 3, delay: float = 2.0) -> str | None:
    """Call OpenAI GPT asynchronously with retry logic."""
    for attempt in range(retries):
        try:
            response = await openai.ChatCompletion.acreate(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
            )
            return response.choices[0].message["content"]
        except Exception as exc:  # pragma: no cover - network issues
            logging.warning("GPT í˜¸ì¶œ ì‹¤íŒ¨ %s/%s: %s", attempt + 1, retries, exc)
            if attempt < retries - 1:
                await asyncio.sleep(delay * (attempt + 1))
    return None

# ---------------------- ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ ----------------------
async def process_keyword(item: dict, existing: dict, sem: asyncio.Semaphore):
    """Process a single keyword entry using the GPT API."""
    keyword = item.get("keyword")
    if not keyword:
        logging.warning("â›” ë¹ˆ í‚¤ì›Œë“œ í•­ëª©, ê±´ë„ˆëœë‹ˆë‹¤.")
        return "skip", None

    if keyword in existing:
        logging.info("â­ï¸ ì¤‘ë³µ ìŠ¤í‚µ: %s", keyword)
        return "skip", None

    prompt = generate_hook_prompt(
        keyword=keyword,
        topic=keyword.split()[0],
        source=item.get("source"),
        score=item.get("score", 0),
        growth=item.get("growth", 0),
        mentions=item.get("mentions", 0),
    )

    async with sem:
        response = await get_gpt_response(prompt)
        await asyncio.sleep(API_DELAY)

    result: dict = {
        "keyword": keyword,
        "hook_prompt": prompt,
        "timestamp": datetime.utcnow().isoformat() + "Z",
    }

    if response:
        lines = response.split("\n")
        result.update(
            {
                "hook_lines": lines[0:2],
                "blog_paragraphs": lines[2:5],
                "video_titles": lines[5:],
                "generated_text": response,
            }
        )
        logging.info("âœ… ìƒì„± ì™„ë£Œ: %s", keyword)
        return "success", result

    result["generated_text"] = None
    result["error"] = "GPT ì‘ë‹µ ì‹¤íŒ¨"
    logging.error("âŒ ìƒì„± ì‹¤íŒ¨: %s", keyword)
    return "failed", result


async def generate_hooks() -> None:
    if not OPENAI_API_KEY:
        logging.error("â— OpenAI API í‚¤ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. .env íŒŒì¼ í™•ì¸ í•„ìš”")
        return

    try:
        with open(KEYWORD_JSON_PATH, 'r', encoding='utf-8') as f:
            data = json.load(f)
            keywords = data.get("filtered_keywords", [])
    except Exception as e:
        logging.error(f"â— í‚¤ì›Œë“œ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        return

    existing = {}
    if os.path.exists(HOOK_OUTPUT_PATH):
        try:
            with open(HOOK_OUTPUT_PATH, 'r', encoding='utf-8') as f:
                existing_data = json.load(f)
                for entry in existing_data:
                    existing[entry['keyword']] = entry
        except Exception as e:
            logging.warning(f"ê¸°ì¡´ ê²°ê³¼ ë¡œë”© ì‹¤íŒ¨: {e}")

    new_output: list[dict] = []
    failed_output: list[dict] = []
    skipped = success = failed = 0

    sem = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)
    tasks = [process_keyword(item, existing, sem) for item in keywords]

    for coro in asyncio.as_completed(tasks):
        status, result = await coro
        if status == "skip":
            skipped += 1
            continue
        if result is None:
            failed += 1
            continue

        if status == "success":
            new_output.append(result)
            success += 1
        else:
            failed_output.append(result)
            failed += 1

    full_output = list(existing.values()) + new_output
    os.makedirs(os.path.dirname(HOOK_OUTPUT_PATH), exist_ok=True)
    with open(HOOK_OUTPUT_PATH, 'w', encoding='utf-8') as f:
        json.dump(full_output, f, ensure_ascii=False, indent=2)

    if failed_output:
        os.makedirs(os.path.dirname(FAILED_HOOK_PATH), exist_ok=True)
        with open(FAILED_HOOK_PATH, 'w', encoding='utf-8') as f:
            json.dump(failed_output, f, ensure_ascii=False, indent=2)
        logging.warning(f"âš ï¸ ì‹¤íŒ¨ í›„í‚¹ ì €ì¥ ì™„ë£Œ: {FAILED_HOOK_PATH}")

    logging.info("ğŸ“Š ìƒì„± ì‘ì—… ìš”ì•½")
    logging.info(f"ì´ í‚¤ì›Œë“œ: {len(keywords)} | ì„±ê³µ: {success} | ì¤‘ë³µìŠ¤í‚µ: {skipped} | ì‹¤íŒ¨: {failed}")
    logging.info(f"ğŸ‰ í›„í‚¹ ë¬¸ì¥ ì €ì¥ ì™„ë£Œ: {HOOK_OUTPUT_PATH}")

if __name__ == "__main__":
    asyncio.run(generate_hooks())
