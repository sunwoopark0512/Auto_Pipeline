#!/usr/bin/env python3
"""
rag_pipeline.py
RAG ê¸°ë°˜ ì›ê³  ìë™ ìƒì„±ê¸°:
1. í‚¤ì›Œë“œ ê¸°ë°˜ ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰
2. ìš”ì•½ ì •ë¦¬ ë° GPTì— ì „ë‹¬
3. SEO ì¹œí™”ì  ì›ê³  ìë™ ìƒì„±
"""

import json
import os
from typing import List

import requests

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")  # í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°


def search_web(query: str, num_results: int = 3) -> List[str]:
    """Perplexity API ë˜ëŠ” Bing/SerpAPIë¡œ ëŒ€ì²´ ê°€ëŠ¥"""
    # ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œë¡œ Serper.dev API ì‚¬ìš©
    url = "https://google.serper.dev/search"
    headers = {
        "X-API-KEY": os.getenv("SERPER_API_KEY"),
        "Content-Type": "application/json",
    }
    payload = {"q": query, "num": num_results}
    response = requests.post(url, headers=headers, data=json.dumps(payload), timeout=10)
    results = response.json()
    return [r["snippet"] for r in results.get("organic", [])]


def summarize_context(snippets: List[str]) -> str:
    """ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½"""
    context = "\n".join(snippets)
    return f"ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìš”ì•½í•´ì¤˜:\n{context}"


def generate_article(topic: str, context_summary: str) -> str:
    """GPTë¥¼ í™œìš©í•œ SEO ì¹œí™”ì  ì›ê³  ìë™ ìƒì„±"""
    prompt = f"""ë‹¹ì‹ ì€ SEO ìµœì í™” ì½˜í…ì¸  ì‘ê°€ì…ë‹ˆë‹¤.
ì£¼ì œ: {topic}
ë°°ê²½ ì •ë³´: {context_summary}
ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í¥ë¯¸ë¡­ê³  êµ¬ì¡°í™”ëœ ë¸”ë¡œê·¸ ì›ê³ ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
í˜•ì‹: ì œëª© + ë¶€ì œëª© + ë³¸ë¬¸ (3~5 ë¬¸ë‹¨)"""

    response = requests.post(
        "https://api.openai.com/v1/chat/completions",
        headers={"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"},
        json={
            "model": "gpt-4",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.7,
        },
        timeout=30,
    )
    return response.json()["choices"][0]["message"]["content"]


def save_article(title: str, content: str, filename: str | None = None) -> None:
    """ì›ê³  ì €ì¥ (Markdown)"""
    os.makedirs("generated_articles", exist_ok=True)
    if not filename:
        filename = title.replace(" ", "_") + ".md"
    with open(f"generated_articles/{filename}", "w", encoding="utf-8") as f:
        f.write(f"# {title}\n\n{content}")
    print(f"âœ… ì›ê³  ì €ì¥ ì™„ë£Œ â†’ generated_articles/{filename}")


def run_rag_pipeline(topic: str) -> None:
    """ì „ì²´ ì‹¤í–‰ íŒŒì´í”„ë¼ì¸"""
    print(f"ğŸ” '{topic}' ì£¼ì œ ê²€ìƒ‰ ì¤‘...")
    snippets = search_web(topic)
    context = summarize_context(snippets)
    article = generate_article(topic, context)
    save_article(topic, article)


if __name__ == "__main__":
    run_rag_pipeline("2025ë…„ ì—¬í–‰ íŠ¸ë Œë“œ")
