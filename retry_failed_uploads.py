import os
import json
import time
import logging
from datetime import datetime
from notion_client import Client
from dotenv import load_dotenv
from scripts.utils import truncate_text, create_notion_page

# ---------------------- ì„¤ì • ë¡œë”© ----------------------
load_dotenv()
NOTION_TOKEN = os.getenv("NOTION_API_TOKEN")
NOTION_HOOK_DB_ID = os.getenv("NOTION_HOOK_DB_ID")
FAILED_PATH = os.getenv("REPARSED_OUTPUT_PATH", "logs/failed_keywords_reparsed.json")
RETRY_DELAY = float(os.getenv("RETRY_DELAY", "0.5"))

logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s:%(message)s')

# ---------------------- Notion í´ë¼ì´ì–¸íŠ¸ ----------------------
if not NOTION_TOKEN or not NOTION_HOOK_DB_ID:
    logging.error("â— í™˜ê²½ ë³€ìˆ˜(NOTION_API_TOKEN, NOTION_HOOK_DB_ID)ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
    exit(1)
notion = Client(auth=NOTION_TOKEN)

# ---------------------- ì‹¤íŒ¨ í‚¤ì›Œë“œ ë¡œë”© ----------------------
def load_failed_items():
    if not os.path.exists(FAILED_PATH):
        logging.warning(f"â— ì‹¤íŒ¨ í•­ëª© íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {FAILED_PATH}")
        return []
    with open(FAILED_PATH, 'r', encoding='utf-8') as f:
        return json.load(f)

# ---------------------- Notion í˜ì´ì§€ ì¬ìƒì„± ----------------------
def create_retry_page(item):
    keyword = item.get("keyword")
    if not keyword:
        raise ValueError("keyword ëˆ„ë½ë¨")

    parsed = item.get("parsed") or {
        "hook_lines": item.get("hook_lines", ["", ""]),
        "blog_paragraphs": item.get("blog_paragraphs", ["", "", ""]),
        "video_titles": item.get("video_titles", ["", ""]),
    }

    create_notion_page(notion, NOTION_HOOK_DB_ID, keyword, parsed)

# ---------------------- ì‹¤í–‰ í•¨ìˆ˜ ----------------------
def retry_failed_uploads():
    failed_items = load_failed_items()
    if not failed_items:
        logging.info("âœ… ì¬ì‹œë„í•  ì‹¤íŒ¨ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    success, failed = 0, 0
    still_failed = []

    for item in failed_items:
        keyword = item.get("keyword")
        if not keyword:
            logging.warning("â›” keyword ëˆ„ë½ í•­ëª© ê±´ë„ˆëœ€")
            continue
        try:
            create_retry_page(item)
            logging.info(f"âœ… ì¬ì—…ë¡œë“œ ì„±ê³µ: {keyword}")
            success += 1
        except Exception as e:
            logging.error(f"âŒ ì¬ì‹œë„ ì‹¤íŒ¨: {keyword} - {e}")
            item["retry_error"] = str(e)
            still_failed.append(item)
            failed += 1
        time.sleep(RETRY_DELAY)

    # ì‹¤íŒ¨ íŒŒì¼ ë®ì–´ì“°ê¸°
    if still_failed:
        with open(FAILED_PATH, 'w', encoding='utf-8') as f:
            json.dump(still_failed, f, ensure_ascii=False, indent=2)
        logging.warning(f"ğŸ” ì—¬ì „íˆ ì‹¤íŒ¨í•œ í•­ëª© {len(still_failed)}ê°œê°€ ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤.")

    # ìš”ì•½
    logging.info("ğŸ“¦ ì¬ì‹œë„ ì—…ë¡œë“œ ìš”ì•½")
    logging.info(f"ì„±ê³µ: {success} | ì‹¤íŒ¨ ìœ ì§€: {failed}")

if __name__ == "__main__":
    retry_failed_uploads()
