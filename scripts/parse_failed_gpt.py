import os
import json
import logging
import re
from dotenv import load_dotenv

load_dotenv()
FAILED_PATH = os.getenv("FAILED_HOOK_PATH", "logs/failed_hooks.json")
OUTPUT_PATH = os.getenv("REPARSED_OUTPUT_PATH", "logs/failed_keywords_reparsed.json")

logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s:%(message)s')

# Reuse parsing logic similar to notion_hook_uploader

def parse_generated_text(text: str):
    hook_lines = re.findall(r"í›„í‚¹ ?ë¬¸ì¥[0-9]?[\s:ï¼š\-\)]*([^\n]+)", text)
    blog_match = re.search(r"ë¸”ë¡œê·¸(?:\s*ì´ˆì•ˆ)?[\s:ï¼š\-\)]*(.*?)\n+\s*(.*?\n+.*?\n+.*?)(?:\n|$)", text, re.DOTALL)
    video_titles = re.findall(r"(?:ì˜ìƒ ì œëª©|YouTube ì œëª©)[\s:ï¼š\-\)]*[^\n]*\n?-\s*(.+)", text)

    blog_paragraphs = [p.strip() for p in blog_match[1].strip().split('\n')[:3]] if blog_match else ["", "", ""]
    return {
        "hook_lines": hook_lines[:2] if len(hook_lines) >= 2 else ["", ""],
        "blog_paragraphs": blog_paragraphs,
        "video_titles": video_titles[:2] if video_titles else ["", ""]
    }

def parse_failed():
    if not os.path.exists(FAILED_PATH):
        logging.error(f"âŒ ì‹¤íŒ¨ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {FAILED_PATH}")
        return

    with open(FAILED_PATH, 'r', encoding='utf-8') as f:
        items = json.load(f)

    results = []
    for item in items:
        text = item.get("generated_text") or ""
        if not text:
            item["retry_error"] = "no_generated_text"
            results.append(item)
            continue
        parsed = parse_generated_text(text)
        item["parsed"] = parsed
        results.append(item)

    os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)
    with open(OUTPUT_PATH, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    logging.info(f"ğŸ“„ ì¬íŒŒì‹± ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {OUTPUT_PATH}")
    logging.info(f"ì´ í•­ëª©: {len(results)}")

if __name__ == "__main__":
    parse_failed()
