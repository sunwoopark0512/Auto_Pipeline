import os
import json
import logging
from dotenv import load_dotenv

load_dotenv()
FAILED_HOOK_PATH = os.getenv("FAILED_HOOK_PATH", "logs/failed_hooks.json")
REPARSED_OUTPUT_PATH = os.getenv("REPARSED_OUTPUT_PATH", "logs/failed_keywords_reparsed.json")

logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s:%(message)s')


def parse_gpt_output(text: str):
    """Parse raw GPT text into structured fields."""
    lines = [line.strip() for line in text.splitlines() if line.strip()]
    return {
        "hook_lines": lines[:2],
        "blog_paragraphs": lines[2:5],
        "video_titles": lines[5:],
    }


def reparse_failed_items():
    if not os.path.exists(FAILED_HOOK_PATH):
        logging.error(f"âŒ ì‹¤íŒ¨ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {FAILED_HOOK_PATH}")
        return

    try:
        with open(FAILED_HOOK_PATH, 'r', encoding='utf-8') as f:
            failed_items = json.load(f)
    except Exception as e:
        logging.error(f"âŒ ì‹¤íŒ¨ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        return

    reparsed = []
    for item in failed_items:
        keyword = item.get("keyword")
        text = item.get("generated_text")
        if not keyword or not text:
            logging.warning("â›” keyword ë˜ëŠ” generated_text ëˆ„ë½ í•­ëª© ê±´ë„ˆëœ€")
            continue
        try:
            parsed = parse_gpt_output(text)
            item.update(parsed)
            reparsed.append(item)
            logging.info(f"âœ… íŒŒì‹± ì„±ê³µ: {keyword}")
        except Exception as e:
            logging.error(f"âŒ íŒŒì‹± ì‹¤íŒ¨: {keyword} - {e}")
            item["parse_error"] = str(e)
            reparsed.append(item)

    os.makedirs(os.path.dirname(REPARSED_OUTPUT_PATH), exist_ok=True)
    with open(REPARSED_OUTPUT_PATH, 'w', encoding='utf-8') as f:
        json.dump(reparsed, f, ensure_ascii=False, indent=2)
    logging.info(f"ğŸ“„ íŒŒì‹± ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {REPARSED_OUTPUT_PATH}")


if __name__ == "__main__":
    reparse_failed_items()
