import os
import json
import time
import logging
from datetime import datetime
from notion_client import Client
from dotenv import load_dotenv

# ---------------------- ì„¤ì • ë¡œë”© ----------------------
load_dotenv()
NOTION_TOKEN = os.getenv("NOTION_API_TOKEN")
NOTION_HOOK_DB_ID = os.getenv("NOTION_HOOK_DB_ID")
FAILED_PATH = os.getenv("FAILED_HOOK_PATH", "logs/failed_keywords_reparsed.json")
RETRY_DELAY = float(os.getenv("RETRY_DELAY", "0.5"))

logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s:%(message)s')

# ---------------------- Notion í´ë¼ì´ì–¸íŠ¸ ----------------------
if not NOTION_TOKEN or not NOTION_HOOK_DB_ID:
    logging.error("â— í™˜ê²½ ë³€ìˆ˜(NOTION_API_TOKEN, NOTION_HOOK_DB_ID)ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
    exit(1)
notion = Client(auth=NOTION_TOKEN)

# ---------------------- ìœ í‹¸: rich_text ê¸¸ì´ ì œí•œ ----------------------
def truncate_text(text, max_length=2000):
    return text if len(text) <= max_length else text[:max_length]

# ---------------------- ì‹¤íŒ¨ í‚¤ì›Œë“œ ë¡œë”© ----------------------
def load_failed_items():
    if not os.path.exists(FAILED_PATH):
        logging.warning(f"â— ì‹¤íŒ¨ í•­ëª© íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {FAILED_PATH}")
        return []
    with open(FAILED_PATH, 'r', encoding='utf-8') as f:
        return json.load(f)

# ---------------------- Notion í˜ì´ì§€ ì¬ìƒì„± ----------------------
def create_retry_page(item):
    keyword = item.get('keyword')
    if not keyword:
        raise ValueError("keyword ëˆ„ë½ë¨")

    topic = keyword.split()[0] if " " in keyword else keyword

    parsed = item.get("parsed") or {
        "hook_lines": item.get("hook_lines", ["", ""]),
        "blog_paragraphs": item.get("blog_paragraphs", ["", "", ""]),
        "video_titles": item.get("video_titles", ["", ""])
    }

    notion.pages.create(
        parent={"database_id": NOTION_HOOK_DB_ID},
        properties={
            "í‚¤ì›Œë“œ": {"title": [{"text": {"content": keyword}}]},
            "ì±„ë„": {"select": {"name": topic}},
            "ë“±ë¡ì¼": {"date": {"start": datetime.utcnow().isoformat() + 'Z'}},
            "í›„í‚¹ë¬¸1": {"rich_text": [{"text": {"content": truncate_text(parsed["hook_lines"][0])}}]},
            "í›„í‚¹ë¬¸2": {"rich_text": [{"text": {"content": truncate_text(parsed["hook_lines"][1])}}]},
            "ë¸”ë¡œê·¸ì´ˆì•ˆ": {"rich_text": [{"text": {"content": truncate_text('\n'.join(parsed["blog_paragraphs"]))}}]},
            "ì˜ìƒì œëª©": {"rich_text": [{"text": {"content": truncate_text('\n'.join(parsed["video_titles"]))}}]}
        }
    )

# ---------------------- ì‹¤í–‰ í•¨ìˆ˜ ----------------------
def retry_failed_uploads():
    failed_items = load_failed_items()
    if not failed_items:
        logging.info("âœ… ì¬ì‹œë„í•  ì‹¤íŒ¨ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    success, failed = 0, 0
    still_failed = []

    for item in failed_items:
        keyword = item.get("keyword")
        if not keyword:
            logging.warning("â›” keyword ëˆ„ë½ í•­ëª© ê±´ë„ˆëœ€")
            continue
        try:
            create_retry_page(item)
            logging.info(f"âœ… ì¬ì—…ë¡œë“œ ì„±ê³µ: {keyword}")
            success += 1
        except Exception as e:
            logging.error(f"âŒ ì¬ì‹œë„ ì‹¤íŒ¨: {keyword} - {e}")
            item["retry_error"] = str(e)
            still_failed.append(item)
            failed += 1
        time.sleep(RETRY_DELAY)

    # ì‹¤íŒ¨ íŒŒì¼ ë®ì–´ì“°ê¸°
    if still_failed:
        with open(FAILED_PATH, 'w', encoding='utf-8') as f:
            json.dump(still_failed, f, ensure_ascii=False, indent=2)
        logging.warning(f"ğŸ” ì—¬ì „íˆ ì‹¤íŒ¨í•œ í•­ëª© {len(still_failed)}ê°œê°€ ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤.")

    # ìš”ì•½
    logging.info("ğŸ“¦ ì¬ì‹œë„ ì—…ë¡œë“œ ìš”ì•½")
    logging.info(f"ì„±ê³µ: {success} | ì‹¤íŒ¨ ìœ ì§€: {failed}")

if __name__ == "__main__":
    retry_failed_uploads()
