import os
import json
import time
import logging
from datetime import datetime
from notion_client import Client
import config

# ---------------------- ÏÑ§Ï†ï Î°úÎî© ----------------------
NOTION_TOKEN = config.NOTION_API_TOKEN
NOTION_HOOK_DB_ID = config.NOTION_HOOK_DB_ID
FAILED_PATH = config.FAILED_HOOK_PATH
RETRY_DELAY = config.RETRY_DELAY
config.require("NOTION_API_TOKEN", "NOTION_HOOK_DB_ID")

logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s:%(message)s')

# ---------------------- Notion ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ ----------------------
notion = Client(auth=NOTION_TOKEN)

# ---------------------- Ïú†Ìã∏: rich_text Í∏∏Ïù¥ Ï†úÌïú ----------------------
def truncate_text(text, max_length=2000):
    return text if len(text) <= max_length else text[:max_length]

# ---------------------- Ïã§Ìå® ÌÇ§ÏõåÎìú Î°úÎî© ----------------------
def load_failed_items():
    if not os.path.exists(FAILED_PATH):
        logging.warning(f"‚ùó Ïã§Ìå® Ìï≠Î™© ÌååÏùºÏù¥ Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏäµÎãàÎã§: {FAILED_PATH}")
        return []
    with open(FAILED_PATH, 'r', encoding='utf-8') as f:
        return json.load(f)

# ---------------------- Notion ÌéòÏù¥ÏßÄ Ïû¨ÏÉùÏÑ± ----------------------
def create_retry_page(item):
    keyword = item.get('keyword')
    if not keyword:
        raise ValueError("keyword ÎàÑÎùΩÎê®")

    topic = keyword.split()[0] if " " in keyword else keyword

    parsed = item.get("parsed") or {
        "hook_lines": item.get("hook_lines", ["", ""]),
        "blog_paragraphs": item.get("blog_paragraphs", ["", "", ""]),
        "video_titles": item.get("video_titles", ["", ""])
    }

    notion.pages.create(
        parent={"database_id": NOTION_HOOK_DB_ID},
        properties={
            "ÌÇ§ÏõåÎìú": {"title": [{"text": {"content": keyword}}]},
            "Ï±ÑÎÑê": {"select": {"name": topic}},
            "Îì±Î°ùÏùº": {"date": {"start": datetime.utcnow().isoformat() + 'Z'}},
            "ÌõÑÌÇπÎ¨∏1": {"rich_text": [{"text": {"content": truncate_text(parsed["hook_lines"][0])}}]},
            "ÌõÑÌÇπÎ¨∏2": {"rich_text": [{"text": {"content": truncate_text(parsed["hook_lines"][1])}}]},
            "Î∏îÎ°úÍ∑∏Ï¥àÏïà": {"rich_text": [{"text": {"content": truncate_text('\n'.join(parsed["blog_paragraphs"]))}}]},
            "ÏòÅÏÉÅÏ†úÎ™©": {"rich_text": [{"text": {"content": truncate_text('\n'.join(parsed["video_titles"]))}}]}
        }
    )

# ---------------------- Ïã§Ìñâ Ìï®Ïàò ----------------------
def retry_failed_uploads():
    failed_items = load_failed_items()
    if not failed_items:
        logging.info("‚úÖ Ïû¨ÏãúÎèÑÌï† Ïã§Ìå® Ìï≠Î™©Ïù¥ ÏóÜÏäµÎãàÎã§.")
        return

    success, failed = 0, 0
    still_failed = []

    for item in failed_items:
        keyword = item.get("keyword")
        if not keyword:
            logging.warning("‚õî keyword ÎàÑÎùΩ Ìï≠Î™© Í±¥ÎÑàÎúÄ")
            continue
        try:
            create_retry_page(item)
            logging.info(f"‚úÖ Ïû¨ÏóÖÎ°úÎìú ÏÑ±Í≥µ: {keyword}")
            success += 1
        except Exception as e:
            logging.error(f"‚ùå Ïû¨ÏãúÎèÑ Ïã§Ìå®: {keyword} - {e}")
            item["retry_error"] = str(e)
            still_failed.append(item)
            failed += 1
        time.sleep(RETRY_DELAY)

    # Ïã§Ìå® ÌååÏùº ÎçÆÏñ¥Ïì∞Í∏∞
    if still_failed:
        with open(FAILED_PATH, 'w', encoding='utf-8') as f:
            json.dump(still_failed, f, ensure_ascii=False, indent=2)
        logging.warning(f"üîÅ Ïó¨Ï†ÑÌûà Ïã§Ìå®Ìïú Ìï≠Î™© {len(still_failed)}Í∞úÍ∞Ä ÎÇ®ÏïÑ ÏûàÏäµÎãàÎã§.")

    # ÏöîÏïΩ
    logging.info("üì¶ Ïû¨ÏãúÎèÑ ÏóÖÎ°úÎìú ÏöîÏïΩ")
    logging.info(f"ÏÑ±Í≥µ: {success} | Ïã§Ìå® Ïú†ÏßÄ: {failed}")

if __name__ == "__main__":
    retry_failed_uploads()
